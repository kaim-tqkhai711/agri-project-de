const path = require("path");
const fs = require("fs");
const readline = require("readline"); // ThÆ° viá»‡n Ä‘á»c file theo dÃ²ng
const db = require("../models");
const Product = db.products;

// Cáº¥u hÃ¬nh
const BACKUP_DIR = path.join(__dirname, "../../backups");
if (!fs.existsSync(BACKUP_DIR)) fs.mkdirSync(BACKUP_DIR);
// Äá»•i Ä‘uÃ´i file thÃ nh .jsonl (JSON Lines) - Má»—i dÃ²ng lÃ  1 object JSON
const BACKUP_FILE = path.join(BACKUP_DIR, "agri_db_bigdata.jsonl"); 

// --- 1. BACKUP (STREAMING WRITE) ---
exports.backup = async (req, res) => {
  console.log("âš¡ [BACKUP] Äang báº¯t Ä‘áº§u Streaming Backup...");
  
  try {
    const writeStream = fs.createWriteStream(BACKUP_FILE);
    
    // Sá»­ dá»¥ng Cursor: Äá»c dá»¯ liá»‡u tá»« MongoDB tá»«ng cÃ¡i má»™t, khÃ´ng load háº¿t vÃ o RAM
    const cursor = Product.find({}).lean().cursor();

    let count = 0;
    
    // Duyá»‡t qua tá»«ng document báº±ng cursor
    for await (const doc of cursor) {
      // Chuyá»ƒn object thÃ nh string vÃ  ghi vÃ o file + xuá»‘ng dÃ²ng
      const line = JSON.stringify(doc) + "\n";
      
      // Kiá»ƒm tra xem buffer cÃ³ Ä‘áº§y khÃ´ng Ä‘á»ƒ chá» (trÃ¡nh trÃ n RAM khi ghi file)
      if (!writeStream.write(line)) {
        await new Promise(resolve => writeStream.once('drain', resolve));
      }
      count++;
    }

    writeStream.end();

    console.log(`âœ… [BACKUP SUCCESS] ÄÃ£ ghi ${count} dÃ²ng.`);
    res.json({ 
      success: true, 
      log: `âœ… BACKUP STREAMING THÃ€NH CÃ”NG!\nğŸ“ File: .jsonl (JSON Lines)\nğŸ“Š Sá»‘ lÆ°á»£ng: ${count.toLocaleString()} báº£n ghi.\nğŸš€ RAM Usage: Tá»‘i Æ°u (<50MB).` 
    });

  } catch (error) {
    console.error("âŒ [BACKUP ERROR]", error);
    res.status(500).json({ success: false, log: `Lá»—i: ${error.message}` });
  }
};

// --- 2. RESTORE (STREAMING READ & BATCH INSERT) ---
exports.restore = async (req, res) => {
  console.log("âš¡ [RESTORE] Äang báº¯t Ä‘áº§u Streaming Restore...");

  if (!fs.existsSync(BACKUP_FILE)) {
    return res.status(400).json({ success: false, log: "âŒ KhÃ´ng tÃ¬m tháº¥y file backup (.jsonl)!" });
  }

  try {
    // BÆ°á»›c 1: XÃ³a sáº¡ch dá»¯ liá»‡u cÅ©
    console.log("ğŸ§¹ Äang xÃ³a dá»¯ liá»‡u cÅ©...");
    await Product.deleteMany({});
    
    // BÆ°á»›c 2: Äá»c file theo dÃ²ng (Line by Line)
    const fileStream = fs.createReadStream(BACKUP_FILE);
    const rl = readline.createInterface({
      input: fileStream,
      crlfDelay: Infinity
    });

    let batch = [];
    const BATCH_SIZE = 2000; // Má»—i láº§n náº¡p 2000 dÃ²ng vÃ o DB
    let totalRestored = 0;

    for await (const line of rl) {
      if (!line.trim()) continue; // Bá» qua dÃ²ng trá»‘ng

      try {
        const doc = JSON.parse(line);
        batch.push(doc);
      } catch (e) {
        console.warn("âš ï¸ Bá» qua dÃ²ng lá»—i JSON");
      }

      // Khi Ä‘á»§ gÃ³i 2000 dÃ²ng thÃ¬ ghi xuá»‘ng DB 1 láº§n
      if (batch.length >= BATCH_SIZE) {
        await Product.insertMany(batch);
        totalRestored += batch.length;
        process.stdout.write(`\râ³ Äang phá»¥c há»“i: ${totalRestored.toLocaleString()} báº£n ghi...`);
        batch = []; // Xáº£ bá»™ nhá»›
      }
    }

    // Ghi ná»‘t sá»‘ cÃ²n dÆ°
    if (batch.length > 0) {
      await Product.insertMany(batch);
      totalRestored += batch.length;
    }

    console.log("\nâœ… [RESTORE SUCCESS]");
    res.json({ 
      success: true, 
      log: `âœ… RESTORE STREAMING THÃ€NH CÃ”NG!\nğŸ”„ ÄÃ£ khÃ´i phá»¥c: ${totalRestored.toLocaleString()} báº£n ghi.\nğŸš€ Ká»¹ thuáº­t: Batch Processing (${BATCH_SIZE}/láº§n).` 
    });

  } catch (error) {
    console.error("âŒ [RESTORE ERROR]", error);
    res.status(500).json({ success: false, log: `Lá»—i: ${error.message}` });
  }
};